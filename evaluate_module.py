import numpy as np #.argmax
import pandas as pd
from sklearn.metrics import f1_score, precision_score, accuracy_score, recall_score, balanced_accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

#labels for dataframe, classification report and confusion matrix
labels=['Basking', 'Blue', 'Hammerhead', 'Mako', 'Sand Tiger', 'Tiger', 'White', 'Blacktip', 'Bull', 'Lemon', 'Nurse', 'Thresher', 'Whale', 'Whitetip']

def create_predictions(model, X_test, y_test):
    #create y_pred predictions and y_text_argmax for metrics
    predictions = model.predict(X_test)

    y_pred = []
    y_test_argmax = []

    for pred in predictions:
        y_pred.append(np.argmax(pred))

    for test in y_test:
        y_test_argmax.append(np.argmax(test))

    return y_pred, y_test_argmax


def model_scoring_metrics(y_test_argmax, y_pred):
    #macro f1
    f1 = f1_score(y_test_argmax, y_pred, average='macro')

    #weighted f1
    f1_score_weighted = f1_score(y_test_argmax, y_pred, average='weighted')

    #macro precision
    precision = precision_score(y_test_argmax, y_pred, average='macro')

    #weighted precision
    precision_score_weighted = precision_score(y_test_argmax, y_pred, average='weighted')

    #macro recall
    recall = recall_score(y_test_argmax,y_pred, average='macro')

    #weighted recall
    recall_weighted = recall_score(y_test_argmax,y_pred, average='weighted')

    #macro accuracy
    accuracy = accuracy_score(y_test_argmax, y_pred)

    #weighted accuracy
    accuracy_bal = balanced_accuracy_score(y_test_argmax, y_pred)


    print(f"Model Scoring Metrics: \n F1 score: {round(f1,4)} \n Weighted F1 score: {round(f1_score_weighted,4)} \n Precision: {round(precision,4)} \n Weighted precision: {round(precision_score_weighted,4)} \n Recall: {round(recall,4)} \n Weighted recall: {round(recall_weighted,4)} \n Accuracy: {round(accuracy,4)} \n Weighted accuracy: {round(accuracy_bal,4)}")

def create_class_report(y_test_argmax, y_pred):

    #classification report - to tidy later
    report = classification_report(y_test_argmax, y_pred, target_names=labels, output_dict=True)

    #Convert the report to a pandas DataFrame and move model accuracy to bottom of df
    accuracy = round(report['accuracy'],4)
    del report['accuracy']
    df = pd.DataFrame(report).transpose()
    df = df.sort_values(by='precision', ascending=False)
    df.reset_index(inplace=True)
    print(f"Scoring Metrics By Class \n {df} \n Model Accuracy: {round(accuracy, 4)*100}%")

def create_confusion_matrix(y_test_argmax, y_pred):
    cm = confusion_matrix(y_test_argmax, y_pred)

    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)

    fig, ax = plt.subplots(figsize=(10,10))
    disp.plot(ax=ax)
    ax.set_xticklabels(labels, rotation=45)

    plt.show()

#TDL STILL TO DO PRELUNCH:
#ADD CONFUSION MATRIX

#BELOW HERE ARE Y_PRED AND Y_TEST_ARGMAX FOR TEXTING, CODE TO TEST FUNCTION IS AT THE BOTTOM



y_pred = [6,
 0,
 10,
 0,
 0,
 0,
 2,
 6,
 8,
 8,
 0,
 13,
 7,
 1,
 7,
 3,
 5,
 13,
 2,
 5,
 13,
 2,
 11,
 11,
 2,
 13,
 4,
 4,
 10,
 6,
 3,
 12,
 13,
 13,
 0,
 8,
 0,
 13,
 5,
 9,
 10,
 2,
 2,
 11,
 2,
 6,
 5,
 2,
 1,
 6,
 9,
 1,
 6,
 5,
 12,
 3,
 5,
 0,
 9,
 11,
 12,
 8,
 11,
 6,
 6,
 2,
 2,
 11,
 7,
 1,
 3,
 1,
 9,
 13,
 0,
 6,
 11,
 13,
 11,
 2,
 9,
 1,
 6,
 8,
 6,
 10,
 1,
 12,
 2,
 13,
 0,
 3,
 13,
 6,
 11,
 0,
 5,
 9,
 8,
 9,
 6,
 2,
 13,
 11,
 13,
 9,
 13,
 12,
 2,
 7,
 13,
 11,
 6,
 8,
 7,
 12,
 10,
 13,
 2,
 9,
 7,
 10,
 9,
 11,
 9,
 10,
 11,
 13,
 3,
 6,
 10,
 2,
 2,
 2,
 7,
 10,
 0,
 7,
 11,
 11,
 13,
 0,
 10,
 3,
 11,
 10,
 10,
 1,
 5,
 5,
 13,
 2,
 10,
 11,
 2,
 4,
 1,
 12,
 6,
 4,
 0,
 8,
 13,
 3,
 13,
 12,
 0,
 13,
 11,
 4,
 3,
 11,
 11,
 12,
 0,
 10,
 11,
 1,
 12,
 9,
 13,
 13,
 11,
 13,
 2,
 4,
 13,
 9,
 0,
 8,
 2,
 13,
 5,
 0,
 12,
 3,
 13,
 5,
 4,
 2,
 10,
 9,
 8,
 8,
 10,
 12,
 2,
 13,
 11,
 8,
 1,
 1,
 8,
 12,
 0,
 11,
 1,
 12,
 0,
 12,
 12,
 6,
 4,
 12,
 6,
 4,
 9,
 9,
 9,
 12,
 5,
 2,
 6,
 12,
 10,
 3,
 11,
 6,
 13,
 2,
 12,
 11,
 5,
 4,
 1,
 6,
 2,
 11,
 12,
 10,
 0,
 5,
 0,
 5,
 11,
 1,
 10,
 3]

y_test_argmax = [6,
 3,
 4,
 0,
 0,
 0,
 2,
 6,
 11,
 2,
 0,
 13,
 9,
 3,
 9,
 13,
 2,
 7,
 2,
 5,
 7,
 2,
 11,
 11,
 13,
 13,
 4,
 4,
 1,
 6,
 3,
 12,
 13,
 13,
 0,
 5,
 5,
 13,
 1,
 6,
 8,
 10,
 2,
 10,
 13,
 6,
 5,
 7,
 13,
 12,
 9,
 1,
 12,
 5,
 12,
 3,
 5,
 0,
 9,
 6,
 12,
 8,
 7,
 8,
 13,
 2,
 5,
 11,
 7,
 1,
 3,
 3,
 2,
 10,
 0,
 6,
 11,
 9,
 11,
 6,
 4,
 11,
 6,
 9,
 6,
 7,
 3,
 12,
 2,
 6,
 0,
 3,
 13,
 3,
 1,
 0,
 11,
 7,
 13,
 9,
 6,
 1,
 1,
 11,
 13,
 6,
 13,
 11,
 13,
 3,
 13,
 2,
 11,
 8,
 9,
 12,
 11,
 10,
 2,
 6,
 11,
 10,
 2,
 2,
 10,
 7,
 1,
 1,
 4,
 3,
 4,
 8,
 2,
 2,
 2,
 7,
 6,
 7,
 11,
 9,
 13,
 7,
 4,
 3,
 11,
 2,
 13,
 11,
 5,
 5,
 6,
 2,
 12,
 12,
 2,
 5,
 1,
 13,
 1,
 9,
 1,
 1,
 13,
 6,
 6,
 12,
 13,
 1,
 11,
 3,
 3,
 2,
 2,
 12,
 0,
 8,
 11,
 12,
 12,
 3,
 13,
 9,
 6,
 1,
 2,
 3,
 9,
 8,
 8,
 8,
 2,
 2,
 8,
 6,
 12,
 1,
 13,
 5,
 7,
 13,
 10,
 7,
 4,
 3,
 13,
 12,
 12,
 13,
 6,
 8,
 1,
 6,
 8,
 2,
 11,
 6,
 8,
 12,
 3,
 12,
 7,
 9,
 4,
 12,
 12,
 4,
 7,
 10,
 4,
 0,
 9,
 2,
 13,
 12,
 10,
 1,
 13,
 3,
 7,
 2,
 12,
 11,
 7,
 4,
 11,
 2,
 5,
 11,
 12,
 8,
 2,
 5,
 9,
 9,
 11,
 3,
 5,
 7]

# model_scoring_metrics(y_test_argmax, y_pred)

create_class_report(y_test_argmax, y_pred)

create_confusion_matrix(y_test_argmax, y_pred)

#I AM CHANGING SOME STUFf
